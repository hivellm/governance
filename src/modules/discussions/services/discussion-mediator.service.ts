import { Injectable, Logger } from '@nestjs/common';
import { ModelCallerService } from './model-caller.service';

export interface MediatorDecision {
  nextModel: string;
  contextualPrompt: string;
  reasoning: string;
  discussionPhase: 'initial' | 'analysis' | 'debate' | 'consensus' | 'conclusion';
}

@Injectable()
export class DiscussionMediatorService {
  private readonly logger = new Logger(DiscussionMediatorService.name);

  constructor(private readonly modelCallerService: ModelCallerService) {}

  /**
   * Use 'auto' model to analyze discussion and decide next steps
   */
  async mediateDiscussion(
    proposalTitle: string,
    proposalContent: string,
    existingComments: any[],
    availableModels: string[]
  ): Promise<MediatorDecision> {
    this.logger.log(`ü§î Mediating discussion with ${existingComments.length} existing comments`);

    const mediatorPrompt = this.createMediatorPrompt(
      proposalTitle,
      proposalContent,
      existingComments,
      availableModels
    );

    try {
      const mediatorResponse = await this.modelCallerService.callLLM('auto', mediatorPrompt);
      return this.parseMediatorResponse(mediatorResponse, availableModels);
    } catch (error) {
      this.logger.error(`Mediator failed: ${error.message}`);
      // Fallback decision
      return this.createFallbackDecision(existingComments, availableModels);
    }
  }

  /**
   * Create mediator prompt for 'auto' model
   */
  private createMediatorPrompt(
    title: string,
    content: string,
    existingComments: any[],
    availableModels: string[]
  ): string {
    let commentsContext = '';
    
    if (existingComments.length > 0) {
      commentsContext = '\n\nCOMENT√ÅRIOS EXISTENTES:\n';
      existingComments.forEach((comment, index) => {
        commentsContext += `${index + 1}. ${comment.authorId} (${comment.type}): ${comment.content}\n\n`;
      });
    }

    return `Voc√™ √© o mediador 'auto' de uma discuss√£o de governan√ßa. Sua fun√ß√£o √© analisar a discuss√£o atual e decidir qual modelo deve comentar a seguir para criar uma discuss√£o rica e construtiva.

PROPOSTA EM DISCUSS√ÉO:
T√≠tulo: ${title}
Conte√∫do: ${content.substring(0, 500)}${content.length > 500 ? '...' : ''}
${commentsContext}

MODELOS DISPON√çVEIS: ${availableModels.join(', ')}

INSTRU√á√ïES:
1. Analise os coment√°rios existentes e identifique lacunas na discuss√£o
2. Escolha o pr√≥ximo modelo mais adequado para adicionar valor
3. Crie um prompt espec√≠fico que incentive esse modelo a responder aos pontos levantados
4. Evite repetir modelos que j√° comentaram recentemente

RESPONDA NO FORMATO:
MODELO_ESCOLHIDO: [id do modelo]
REASONING: [sua an√°lise do porqu√™ escolheu este modelo]
PROMPT_ESPEC√çFICO: [prompt direcionado para o modelo escolhido]
FASE_DISCUSS√ÉO: [initial|analysis|debate|consensus|conclusion]

Seja estrat√©gico na escolha para criar uma discuss√£o din√¢mica entre os modelos.`;
  }

  /**
   * Parse mediator response to extract decision
   */
  private parseMediatorResponse(response: string, availableModels: string[]): MediatorDecision {
    const lines = response.split('\n');
    let nextModel = '';
    let reasoning = '';
    let contextualPrompt = '';
    let discussionPhase: MediatorDecision['discussionPhase'] = 'analysis';

    for (const line of lines) {
      const trimmedLine = line.trim();
      
      if (trimmedLine.startsWith('MODELO_ESCOLHIDO:')) {
        nextModel = trimmedLine.replace('MODELO_ESCOLHIDO:', '').trim();
      } else if (trimmedLine.startsWith('REASONING:')) {
        reasoning = trimmedLine.replace('REASONING:', '').trim();
      } else if (trimmedLine.startsWith('PROMPT_ESPEC√çFICO:')) {
        contextualPrompt = trimmedLine.replace('PROMPT_ESPEC√çFICO:', '').trim();
      } else if (trimmedLine.startsWith('FASE_DISCUSS√ÉO:')) {
        const phase = trimmedLine.replace('FASE_DISCUSS√ÉO:', '').trim();
        if (['initial', 'analysis', 'debate', 'consensus', 'conclusion'].includes(phase)) {
          discussionPhase = phase as MediatorDecision['discussionPhase'];
        }
      }
    }

    // Validate chosen model
    if (!nextModel || !availableModels.includes(nextModel)) {
      this.logger.warn(`Invalid model chosen: ${nextModel}, using fallback`);
      nextModel = availableModels.find(m => m !== 'auto') || availableModels[0];
    }

    // Ensure we have a contextual prompt
    if (!contextualPrompt) {
      contextualPrompt = `Analise esta proposta e forne√ßa sua perspectiva t√©cnica especializada, considerando os coment√°rios j√° feitos por outros modelos.`;
    }

    return {
      nextModel,
      contextualPrompt,
      reasoning: reasoning || 'An√°lise autom√°tica para diversificar perspectivas',
      discussionPhase
    };
  }

  /**
   * Create fallback decision when mediator fails
   */
  private createFallbackDecision(existingComments: any[], availableModels: string[]): MediatorDecision {
    // Get models that haven't commented yet
    const commentedModels = existingComments.map(c => c.authorId);
    const availableForComment = availableModels.filter(m => 
      m !== 'auto' && !commentedModels.includes(m)
    );

    const nextModel = availableForComment.length > 0 
      ? availableForComment[0] 
      : availableModels.find(m => m !== 'auto') || 'gpt-5';

    return {
      nextModel,
      contextualPrompt: 'Analise esta proposta e forne√ßa sua perspectiva t√©cnica, considerando os coment√°rios anteriores.',
      reasoning: 'Sele√ß√£o autom√°tica para continuar discuss√£o',
      discussionPhase: existingComments.length === 0 ? 'initial' : 'analysis'
    };
  }

  /**
   * Analyze discussion to determine if it should continue
   */
  async shouldContinueDiscussion(
    existingComments: any[],
    maxComments: number = 6
  ): Promise<{ shouldContinue: boolean; reason: string }> {
    if (existingComments.length >= maxComments) {
      return {
        shouldContinue: false,
        reason: `Discuss√£o atingiu limite de ${maxComments} coment√°rios`
      };
    }

    if (existingComments.length === 0) {
      return {
        shouldContinue: true,
        reason: 'Iniciar discuss√£o'
      };
    }

    // Use mediator to decide if discussion should continue
    const mediatorPrompt = `Analise esta discuss√£o e decida se deve continuar:

COMENT√ÅRIOS EXISTENTES:
${existingComments.map((c, i) => `${i + 1}. ${c.authorId}: ${c.content.substring(0, 100)}...`).join('\n')}

A discuss√£o deve continuar? Responda apenas: SIM ou N√ÉO
Motivo: [breve explica√ß√£o]`;

    try {
      const response = await this.modelCallerService.callLLM('auto', mediatorPrompt);
      const shouldContinue = response.toLowerCase().includes('sim');
      
      return {
        shouldContinue,
        reason: response.substring(0, 200)
      };
    } catch (error) {
      // Fallback: continue if less than 4 comments
      return {
        shouldContinue: existingComments.length < 4,
        reason: 'Decis√£o autom√°tica baseada em n√∫mero de coment√°rios'
      };
    }
  }
}
