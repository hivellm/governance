import { Injectable, Logger } from '@nestjs/common';
import { ModelCallerService } from './model-caller.service';

export interface MediatorDecision {
  nextModel: string;
  contextualPrompt: string;
  reasoning: string;
  discussionPhase: 'initial' | 'analysis' | 'debate' | 'consensus' | 'conclusion';
}

@Injectable()
export class DiscussionMediatorService {
  private readonly logger = new Logger(DiscussionMediatorService.name);

  constructor(private readonly modelCallerService: ModelCallerService) {}

  /**
   * Use 'auto' model to analyze discussion and decide next steps
   */
  async mediateDiscussion(
    proposalTitle: string,
    proposalContent: string,
    existingComments: any[],
    availableModels: string[]
  ): Promise<MediatorDecision> {
    this.logger.log(`ü§î Mediating discussion with ${existingComments.length} existing comments`);

    const mediatorPrompt = this.createMediatorPrompt(
      proposalTitle,
      proposalContent,
      existingComments,
      availableModels
    );

    try {
      const mediatorResponse = await this.modelCallerService.callLLM('auto', mediatorPrompt);
      return this.parseMediatorResponse(mediatorResponse, availableModels, existingComments);
    } catch (error) {
      this.logger.error(`Mediator failed: ${error.message}`);
      // Fallback decision
      return this.createFallbackDecision(existingComments, availableModels);
    }
  }

  /**
   * Create mediator prompt for 'auto' model
   */
  private createMediatorPrompt(
    title: string,
    content: string,
    existingComments: any[],
    availableModels: string[]
  ): string {
    // Extract proposal ID from title
    const proposalId = this.extractProposalId(title);
    
    // Build complete comments context with full content
    let commentsContext = '';
    if (existingComments.length > 0) {
      commentsContext = '\n\nHIST√ìRICO COMPLETO DA DISCUSS√ÉO:\n';
      existingComments.forEach((comment, index) => {
        commentsContext += `${index + 1}. MODELO: ${comment.authorId}\n`;
        commentsContext += `   TIPO: ${comment.type}\n`;
        commentsContext += `   CONTE√öDO COMPLETO:\n   ${comment.content}\n\n`;
      });
    }

    // Get unique models that have already commented
    const commentedModels = [...new Set(existingComments.map(c => c.authorId))];
    const lastCommenter = existingComments.length > 0 ? existingComments[existingComments.length - 1].authorId : null;
    
    // Filter available models to avoid consecutive comments
    const availableForNext = availableModels.filter(m => m !== 'auto' && m !== lastCommenter);

    return `Voc√™ √© o mediador 'auto' de uma discuss√£o de governan√ßa. Sua fun√ß√£o √© analisar a discuss√£o atual e decidir qual modelo deve comentar a seguir para criar uma discuss√£o rica e construtiva.

CONTEXTO COMPLETO DA PROPOSTA:
- ID: ${proposalId}
- T√çTULO: ${title}
- CONTE√öDO COMPLETO DA PROPOSTA:
${typeof content === 'string' ? content : JSON.stringify(content, null, 2)}

SITUA√á√ÉO ATUAL DA DISCUSS√ÉO:
- Total de coment√°rios: ${existingComments.length}
- Modelos que j√° comentaram: ${commentedModels.length > 0 ? commentedModels.join(', ') : 'Nenhum'}
- √öltimo comentador: ${lastCommenter || 'Nenhum'}
${commentsContext}

MODELOS DISPON√çVEIS PARA PR√ìXIMO COMENT√ÅRIO: ${availableForNext.join(', ')}

INSTRU√á√ïES PARA MEDIA√á√ÉO:
1. Analise TODA a proposta e TODOS os coment√°rios existentes
2. Identifique lacunas na discuss√£o que precisam ser abordadas
3. Escolha o modelo mais adequado para adicionar valor √∫nico
4. EVITE escolher o √∫ltimo modelo que comentou (${lastCommenter || 'N/A'})
5. Crie um prompt espec√≠fico e completo para o modelo escolhido
6. Inclua no prompt TODA informa√ß√£o necess√°ria (proposta completa + contexto)

IMPORTANTE: O modelo escolhido N√ÉO tem acesso a arquivos externos ou comandos de busca. 
Forne√ßa TODAS as informa√ß√µes necess√°rias no PROMPT_ESPEC√çFICO.

RESPONDA EXATAMENTE NO FORMATO:
MODELO_ESCOLHIDO: [id do modelo]
REASONING: [sua an√°lise detalhada do porqu√™ escolheu este modelo]
PROMPT_ESPEC√çFICO: [prompt completo com TODA informa√ß√£o necess√°ria para an√°lise]
FASE_DISCUSS√ÉO: [initial|analysis|debate|consensus|conclusion]

Seja estrat√©gico na escolha para criar uma discuss√£o din√¢mica e rica entre os modelos.`;
  }

  /**
   * Extract proposal ID from title
   */
  private extractProposalId(title: string): string {
    const match = title.match(/P(\d+)/i);
    if (match) {
      return `P${match[1].padStart(3, '0')}`;
    }
    
    const numberMatch = title.match(/(\d+)/);
    if (numberMatch) {
      return `P${numberMatch[1].padStart(3, '0')}`;
    }
    
    return 'UNKNOWN';
  }

  /**
   * Parse mediator response to extract decision
   */
  private parseMediatorResponse(response: string, availableModels: string[], existingComments: any[] = []): MediatorDecision {
    const lines = response.split('\n');
    let nextModel = '';
    let reasoning = '';
    let contextualPrompt = '';
    let discussionPhase: MediatorDecision['discussionPhase'] = 'analysis';

    for (const line of lines) {
      const trimmedLine = line.trim();
      
      if (trimmedLine.startsWith('MODELO_ESCOLHIDO:')) {
        nextModel = trimmedLine.replace('MODELO_ESCOLHIDO:', '').trim();
      } else if (trimmedLine.startsWith('REASONING:')) {
        reasoning = trimmedLine.replace('REASONING:', '').trim();
      } else if (trimmedLine.startsWith('PROMPT_ESPEC√çFICO:')) {
        contextualPrompt = trimmedLine.replace('PROMPT_ESPEC√çFICO:', '').trim();
      } else if (trimmedLine.startsWith('FASE_DISCUSS√ÉO:')) {
        const phase = trimmedLine.replace('FASE_DISCUSS√ÉO:', '').trim();
        if (['initial', 'analysis', 'debate', 'consensus', 'conclusion'].includes(phase)) {
          discussionPhase = phase as MediatorDecision['discussionPhase'];
        }
      }
    }

    // Get the last commenter to avoid consecutive comments
    const lastCommenter = existingComments.length > 0 ? existingComments[existingComments.length - 1].authorId : null;
    
    // Validate chosen model
    if (!nextModel || !availableModels.includes(nextModel)) {
      this.logger.warn(`Invalid model chosen: ${nextModel}, using fallback`);
      nextModel = availableModels.find(m => m !== 'auto' && m !== lastCommenter) || availableModels[0];
    }
    
    // Prevent consecutive comments from same model
    if (nextModel === lastCommenter) {
      this.logger.warn(`Preventing consecutive comment from ${nextModel}`);
      const alternativeModel = availableModels.find(m => m !== 'auto' && m !== lastCommenter);
      if (alternativeModel) {
        nextModel = alternativeModel;
        reasoning = `Evitando coment√°rios consecutivos, escolhido ${nextModel}`;
      }
    }

    // Ensure we have a contextual prompt
    if (!contextualPrompt) {
      contextualPrompt = this.createComprehensivePrompt(existingComments, nextModel);
    }

    return {
      nextModel,
      contextualPrompt,
      reasoning: reasoning || 'An√°lise autom√°tica para diversificar perspectivas',
      discussionPhase
    };
  }

  /**
   * Create fallback decision when mediator fails
   */
  private createFallbackDecision(existingComments: any[], availableModels: string[]): MediatorDecision {
    // Get the last commenter to avoid consecutive comments from same model
    const lastCommenter = existingComments.length > 0 ? existingComments[existingComments.length - 1].authorId : null;
    
    // Get models that haven't commented yet, excluding 'auto' and last commenter
    const commentedModels = existingComments.map(c => c.authorId);
    let availableForComment = availableModels.filter(m => 
      m !== 'auto' && m !== lastCommenter && !commentedModels.includes(m)
    );

    // If no unused models, allow models that have commented but not the last one
    if (availableForComment.length === 0) {
      availableForComment = availableModels.filter(m => 
        m !== 'auto' && m !== lastCommenter
      );
    }

    // If still no models (shouldn't happen), use any model except auto and last commenter
    if (availableForComment.length === 0) {
      availableForComment = availableModels.filter(m => m !== 'auto' && m !== lastCommenter);
    }

    const nextModel = availableForComment.length > 0 
      ? availableForComment[0] 
      : availableModels.find(m => m !== 'auto') || 'gpt-5';

    // Create comprehensive contextual prompt for fallback
    const contextualPrompt = this.createComprehensivePrompt(existingComments, nextModel);

    return {
      nextModel,
      contextualPrompt,
      reasoning: 'An√°lise autom√°tica para diversificar perspectivas',
      discussionPhase: existingComments.length === 0 ? 'initial' : 'analysis'
    };
  }

  /**
   * Create comprehensive prompt with full context for models
   */
  private createComprehensivePrompt(existingComments: any[], modelId: string): string {
    let commentsHistory = '';
    
    if (existingComments.length > 0) {
      commentsHistory = '\n\nHIST√ìRICO COMPLETO DOS COMENT√ÅRIOS ANTERIORES:\n';
      existingComments.forEach((comment, index) => {
        commentsHistory += `${index + 1}. MODELO: ${comment.authorId}\n`;
        commentsHistory += `   AN√ÅLISE: ${comment.content}\n\n`;
      });
      commentsHistory += 'IMPORTANTE: Considere todos os coment√°rios acima em sua an√°lise. Adicione sua perspectiva √∫nica sem repetir pontos j√° abordados.\n';
    }

    return `Voc√™ √© ${modelId} participando de uma discuss√£o t√©cnica de governan√ßa.

INSTRU√á√ïES ESPEC√çFICAS:
- Voc√™ N√ÉO tem acesso a arquivos externos ou comandos de busca
- TODAS as informa√ß√µes necess√°rias est√£o fornecidas abaixo
- Forne√ßa an√°lise t√©cnica direta em 100-150 palavras
- Foque em aspectos √∫nicos que outros modelos n√£o abordaram
- N√ÉO pe√ßa informa√ß√µes adicionais - analise com base no conte√∫do fornecido

${commentsHistory}

Forne√ßa sua an√°lise t√©cnica especializada considerando:
1. Viabilidade t√©cnica da implementa√ß√£o
2. Arquitetura e integra√ß√£o com sistemas existentes
3. Considera√ß√µes de seguran√ßa e performance
4. Riscos e benef√≠cios espec√≠ficos
5. Recomenda√ß√µes pr√°ticas para implementa√ß√£o

Responda DIRETAMENTE em portugu√™s brasileiro com sua an√°lise t√©cnica.`;
  }

  /**
   * Analyze discussion to determine if it should continue
   */
  async shouldContinueDiscussion(
    existingComments: any[],
    maxComments: number = 6
  ): Promise<{ shouldContinue: boolean; reason: string }> {
    if (existingComments.length >= maxComments) {
      return {
        shouldContinue: false,
        reason: `Discuss√£o atingiu limite de ${maxComments} coment√°rios`
      };
    }

    if (existingComments.length === 0) {
      return {
        shouldContinue: true,
        reason: 'Iniciar discuss√£o'
      };
    }

    // Use mediator to decide if discussion should continue
    const mediatorPrompt = `DECIS√ÉO R√ÅPIDA: Analise esta discuss√£o e decida se deve continuar.

COMENT√ÅRIOS EXISTENTES (${existingComments.length}):
${existingComments.map((c, i) => `${i + 1}. ${c.authorId}: ${c.content.substring(0, 300)}${c.content.length > 300 ? '...' : ''}`).join('\n')}

REGRAS:
- Se h√° menos de 4 coment√°rios: CONTINUAR
- Se h√° diversidade de perspectivas: CONTINUAR  
- Se discuss√£o est√° repetitiva: PARAR
- Se h√° consenso claro: PARAR
- Se apenas 1-2 modelos comentaram: CONTINUAR

RESPONDA APENAS:
SIM - se deve continuar
N√ÉO - se deve parar

Motivo: [m√°ximo 20 palavras]`;

    try {
      const response = await this.modelCallerService.callLLM('auto', mediatorPrompt);
      const lowerResponse = response.toLowerCase();
      
      // Look for explicit YES/NO patterns
      let shouldContinue = false;
      
      if (lowerResponse.includes('sim') || lowerResponse.includes('yes') || 
          lowerResponse.includes('continuar') || lowerResponse.includes('continue')) {
        shouldContinue = true;
      } else if (lowerResponse.includes('n√£o') || lowerResponse.includes('nao') || 
                 lowerResponse.includes('no') || lowerResponse.includes('parar') || 
                 lowerResponse.includes('stop')) {
        shouldContinue = false;
      } else {
        // If no clear decision, be more permissive - continue if we have few comments or few unique models
        const uniqueModels = new Set(existingComments.map(c => c.authorId)).size;
        shouldContinue = existingComments.length < 4 || uniqueModels < 3;
        this.logger.warn(`Mediator gave unclear response: "${response.substring(0, 100)}", defaulting to ${shouldContinue ? 'continue' : 'stop'} (${existingComments.length} comments, ${uniqueModels} models)`);
      }
      
      return {
        shouldContinue,
        reason: response.substring(0, 200)
      };
    } catch (error) {
      // Fallback: continue if less than 4 comments
      return {
        shouldContinue: existingComments.length < 4,
        reason: 'Decis√£o autom√°tica baseada em n√∫mero de coment√°rios'
      };
    }
  }
}
